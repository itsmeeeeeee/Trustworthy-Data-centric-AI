You're GPT4 and are about to start a task where you will be shown some pieces of text taken mostly from older news articles, alongside 4 different possible simplified versions of each text, and you will be asked to evaluate the quality of the simplifications based on some metrics defined below. The purpose of text simplification can be varied, but include things such as making the text easier to read, more accessible to language learners, or explaining a medical or legal text in plain speak. We ask that you carefully read the original text and rank each of the 4 simplifications according to the following metrics, which are defined below.

Semantics, or adequacy: This assesses whether the meaning of the text is preserved further to the simplification. Semantic preservation is assessed on a 5-point Likert scale from 1 (Meaning Not Preserved) to 5 (Meaning fully preserved). NOTE: You should penalize simplified text which is not self contained. For example, if the sentence "Scientists have no idea how eels protect their own brain and muscles from being damaged by electricity" is simplified as "Scientists have no idea how they stay safe", this should be rated around 2 out of 5 as it is not possible by just reading the simplified version to understand what "they" is referring to. Like wise if the simplified text contains hallucinations (facts not contained in the source) it should be penalised. For example if "He yelled" is simplified as "His father Russell shouted" this should be rated around 2 under this category. The omission of some unimportant details from the source into the simplified version is acceptable at your discretion, if the text meaning is preserved.

Grammaticality (or fluency). This assesses whether the simplified text remains grammatical and understandable. Sentences should have no formatting problems, capitalization errors or obviously ungrammatical sentences (e.g., fragments, missing components) that make the text difficult to read. Grammaticality / Fluency is assessed on a 5-point Likert scale from 1 (Not Fluent) to 5 (Super Fluent)

Simplicity. This assesses whether the simplified text, considered in its entirety, is simpler than the source text. Simplicity is assessed on a 5-point Likert scale from 1 (text is significantly more complex than the source) to 5 (text is significantly simpler than the source, or no further simplification was possible). Note that sometimes you may encounter very short sentences which cannot be simplified further and are repeated identically, for example "How are you?". In such cases, even if the text is not simpler than the source, it may be appropriate to assign a score of 5. A score of 3 is appropriate for cases where the text was not simplified nor made more complex, but potential for simplifcation exists.

We will pass you the input you need to rank in json format
Please reply with the scores in json format.
This is an example json query where "original_input" is the source text, 'id' is the unique identifier, and all other keys represent output texts which you need to evaluate.
{"original_input": "He is the first to market a simplified version of the tool to the public , a project that , for now , is not dangerous .", "gold_reference": "Zayner is the first to sell a gene-changing tool to regular people . His set is not dangerous .", "google/flan-t5-xxl": "He is the first to market a simplified version of the tool to the public, a project that, for now, is not dangerous.", "davinci-instruct-beta": "He is the first to market a simplified version of the tool to the public.\n\nHe is the first to market a simplified version of the tool to the public.", "gpt-3.5-turbo": "He created a safer version of the tool and introduced it to the public before anyone else.", "id": "9ec83328fbea94d7cdc4b92aba92f64abaa8727f6c0c99cc3b588b58bb8bb3f5"}

Your answer should contain the id and the scores, for example, if you wish to give gold_reference a semantics score of 2, a grammaticality score of 5 and a simplicity score of 4, and you wish to give google/flan-t5-xxl a semantics score of 5, a grammaticality score of 5, a simplicity score of 4, and you wish to give davinci-instruct-beta a semantics score of 5, a grammaticality score of 5, a simplicity score of 4, and you wish to give gpt-3.5-turbo a semantics score of 5, a grammaticality score of 5 and a simplicity score of 5, then you should return the following output (note how the id item needs to be preserved to allowed for identification):
{"gold_reference": {"semantics": 2, "grammaticality": 5, "simplicity": 4}, "google/flan-t5-xxl": {"semantics": 5, "grammaticality": 5, "simplicity": 4}, "davinci-instruct-beta": {"semantics": 5, "grammaticality": 5, "simplicity": 4}, "gpt-3.5-turbo": {"semantics": 5, "grammaticality": 5, "simplicity": 5}, "id": "9ec83328fbea94d7cdc4b92aba92f64abaa8727f6c0c99cc3b588b58bb8bb3f5"}

Is this clear? Do you have any questions or are you ready to start?